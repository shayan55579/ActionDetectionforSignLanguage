{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33f1544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.11-cp39-cp39-win_amd64.whl (49.0 MB)\n",
      "     -------------------------------------- 49.0/49.0 MB 302.5 kB/s eta 0:00:00\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-win_amd64.whl (42.5 MB)\n",
      "     -------------------------------------- 42.5/42.5 MB 319.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python39\\lib\\site-packages (from mediapipe) (3.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (1.21.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\program files\\python39\\lib\\site-packages (from matplotlib->mediapipe) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\program files\\python39\\lib\\site-packages (from matplotlib->mediapipe) (9.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python39\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->mediapipe) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python39\\lib\\site-packages (from matplotlib->mediapipe) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shayan\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Installing collected packages: opencv-contrib-python, mediapipe\n",
      "Successfully installed mediapipe-0.8.11 opencv-contrib-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a2642",
   "metadata": {},
   "source": [
    "### Import necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a70a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b1f81",
   "metadata": {},
   "source": [
    "### Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c3a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb3bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a01e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b4b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b7c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c567f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb6e99",
   "metadata": {},
   "source": [
    "### Extract Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf32c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark {\n",
       "  x: 0.3516765832901001\n",
       "  y: 0.47473251819610596\n",
       "  z: -0.9374459385871887\n",
       "  visibility: 0.9987444877624512\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3927837610244751\n",
       "  y: 0.4150504469871521\n",
       "  z: -0.9821723699569702\n",
       "  visibility: 0.9977872371673584\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4186602532863617\n",
       "  y: 0.41449907422065735\n",
       "  z: -0.9825353622436523\n",
       "  visibility: 0.9982832074165344\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4432855248451233\n",
       "  y: 0.4144616425037384\n",
       "  z: -0.9830867648124695\n",
       "  visibility: 0.9980258345603943\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3364432752132416\n",
       "  y: 0.4155217111110687\n",
       "  z: -0.8914445042610168\n",
       "  visibility: 0.9969513416290283\n",
       "}\n",
       "landmark {\n",
       "  x: 0.32030946016311646\n",
       "  y: 0.4153755307197571\n",
       "  z: -0.8910976648330688\n",
       "  visibility: 0.9969238042831421\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3048049509525299\n",
       "  y: 0.41562619805336\n",
       "  z: -0.8913924098014832\n",
       "  visibility: 0.9958387613296509\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4933687150478363\n",
       "  y: 0.4394853413105011\n",
       "  z: -0.8834539651870728\n",
       "  visibility: 0.9989562630653381\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3115130364894867\n",
       "  y: 0.43578198552131653\n",
       "  z: -0.4771614670753479\n",
       "  visibility: 0.9973639249801636\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3958832025527954\n",
       "  y: 0.5462407469749451\n",
       "  z: -0.8920086026191711\n",
       "  visibility: 0.9991872906684875\n",
       "}\n",
       "landmark {\n",
       "  x: 0.333829790353775\n",
       "  y: 0.5459516644477844\n",
       "  z: -0.7652726769447327\n",
       "  visibility: 0.9987496137619019\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6414393186569214\n",
       "  y: 0.7488718032836914\n",
       "  z: -0.8038679361343384\n",
       "  visibility: 0.9975132346153259\n",
       "}\n",
       "landmark {\n",
       "  x: 0.24221956729888916\n",
       "  y: 0.6913625001907349\n",
       "  z: -0.11279523372650146\n",
       "  visibility: 0.9969824552536011\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7846165895462036\n",
       "  y: 1.0827858448028564\n",
       "  z: -0.8568083643913269\n",
       "  visibility: 0.5168939232826233\n",
       "}\n",
       "landmark {\n",
       "  x: 0.0307700727134943\n",
       "  y: 0.8697112798690796\n",
       "  z: 0.19740599393844604\n",
       "  visibility: 0.5797382593154907\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7856780290603638\n",
       "  y: 1.4257445335388184\n",
       "  z: -0.9514940977096558\n",
       "  visibility: 0.2937586307525635\n",
       "}\n",
       "landmark {\n",
       "  x: -0.20949482917785645\n",
       "  y: 0.9878905415534973\n",
       "  z: -0.044235359877347946\n",
       "  visibility: 0.3465225100517273\n",
       "}\n",
       "landmark {\n",
       "  x: 0.80854731798172\n",
       "  y: 1.5398262739181519\n",
       "  z: -1.019072413444519\n",
       "  visibility: 0.27060002088546753\n",
       "}\n",
       "landmark {\n",
       "  x: -0.27902621030807495\n",
       "  y: 1.0191646814346313\n",
       "  z: -0.0683048889040947\n",
       "  visibility: 0.28651079535484314\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7663296461105347\n",
       "  y: 1.5245863199234009\n",
       "  z: -1.1139053106307983\n",
       "  visibility: 0.3079577386379242\n",
       "}\n",
       "landmark {\n",
       "  x: -0.2731854319572449\n",
       "  y: 1.0193047523498535\n",
       "  z: -0.19601835310459137\n",
       "  visibility: 0.35009151697158813\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7502896189689636\n",
       "  y: 1.4801170825958252\n",
       "  z: -0.9855297803878784\n",
       "  visibility: 0.3202667236328125\n",
       "}\n",
       "landmark {\n",
       "  x: -0.2407800853252411\n",
       "  y: 1.0190026760101318\n",
       "  z: -0.11900664865970612\n",
       "  visibility: 0.41067075729370117\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5434521436691284\n",
       "  y: 1.460615634918213\n",
       "  z: -0.16621991991996765\n",
       "  visibility: 0.0021101476158946753\n",
       "}\n",
       "landmark {\n",
       "  x: 0.2730242908000946\n",
       "  y: 1.4260143041610718\n",
       "  z: 0.17055825889110565\n",
       "  visibility: 0.002333250595256686\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5098398923873901\n",
       "  y: 2.055295944213867\n",
       "  z: -0.2201496809720993\n",
       "  visibility: 0.0014963720459491014\n",
       "}\n",
       "landmark {\n",
       "  x: 0.25314992666244507\n",
       "  y: 1.9907057285308838\n",
       "  z: 0.09328882396221161\n",
       "  visibility: 0.0007847302476875484\n",
       "}\n",
       "landmark {\n",
       "  x: 0.49690064787864685\n",
       "  y: 2.626189708709717\n",
       "  z: 0.41955429315567017\n",
       "  visibility: 4.309972428018227e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.22984525561332703\n",
       "  y: 2.5982260704040527\n",
       "  z: 0.43790507316589355\n",
       "  visibility: 1.9814573533949442e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.50950026512146\n",
       "  y: 2.7146055698394775\n",
       "  z: 0.45571407675743103\n",
       "  visibility: 3.324963472550735e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.22598771750926971\n",
       "  y: 2.696990489959717\n",
       "  z: 0.45773372054100037\n",
       "  visibility: 4.155090937274508e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4227546155452728\n",
       "  y: 2.804229497909546\n",
       "  z: -0.12455079704523087\n",
       "  visibility: 3.199183993274346e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.22931666672229767\n",
       "  y: 2.786731243133545\n",
       "  z: -0.14326871931552887\n",
       "  visibility: 3.952720726374537e-05\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd22f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4f9dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.35167658,  0.47473252, -0.93744594,  0.99874449]),\n",
       " array([ 0.39278376,  0.41505045, -0.98217237,  0.99778724]),\n",
       " array([ 0.41866025,  0.41449907, -0.98253536,  0.99828321]),\n",
       " array([ 0.44328552,  0.41446164, -0.98308676,  0.99802583]),\n",
       " array([ 0.33644328,  0.41552171, -0.8914445 ,  0.99695134]),\n",
       " array([ 0.32030946,  0.41537553, -0.89109766,  0.9969238 ]),\n",
       " array([ 0.30480495,  0.4156262 , -0.89139241,  0.99583876]),\n",
       " array([ 0.49336872,  0.43948534, -0.88345397,  0.99895626]),\n",
       " array([ 0.31151304,  0.43578199, -0.47716147,  0.99736392]),\n",
       " array([ 0.3958832 ,  0.54624075, -0.8920086 ,  0.99918729]),\n",
       " array([ 0.33382979,  0.54595166, -0.76527268,  0.99874961]),\n",
       " array([ 0.64143932,  0.7488718 , -0.80386794,  0.99751323]),\n",
       " array([ 0.24221957,  0.6913625 , -0.11279523,  0.99698246]),\n",
       " array([ 0.78461659,  1.08278584, -0.85680836,  0.51689392]),\n",
       " array([0.03077007, 0.86971128, 0.19740599, 0.57973826]),\n",
       " array([ 0.78567803,  1.42574453, -0.9514941 ,  0.29375863]),\n",
       " array([-0.20949483,  0.98789054, -0.04423536,  0.34652251]),\n",
       " array([ 0.80854732,  1.53982627, -1.01907241,  0.27060002]),\n",
       " array([-0.27902621,  1.01916468, -0.06830489,  0.2865108 ]),\n",
       " array([ 0.76632965,  1.52458632, -1.11390531,  0.30795774]),\n",
       " array([-0.27318543,  1.01930475, -0.19601835,  0.35009152]),\n",
       " array([ 0.75028962,  1.48011708, -0.98552978,  0.32026672]),\n",
       " array([-0.24078009,  1.01900268, -0.11900665,  0.41067076]),\n",
       " array([ 0.54345214,  1.46061563, -0.16621992,  0.00211015]),\n",
       " array([0.27302429, 1.4260143 , 0.17055826, 0.00233325]),\n",
       " array([ 5.09839892e-01,  2.05529594e+00, -2.20149681e-01,  1.49637205e-03]),\n",
       " array([2.53149927e-01, 1.99070573e+00, 9.32888240e-02, 7.84730248e-04]),\n",
       " array([4.96900648e-01, 2.62618971e+00, 4.19554293e-01, 4.30997243e-05]),\n",
       " array([2.29845256e-01, 2.59822607e+00, 4.37905073e-01, 1.98145735e-05]),\n",
       " array([5.09500265e-01, 2.71460557e+00, 4.55714077e-01, 3.32496347e-05]),\n",
       " array([2.25987718e-01, 2.69699049e+00, 4.57733721e-01, 4.15509094e-05]),\n",
       " array([ 4.22754616e-01,  2.80422950e+00, -1.24550797e-01,  3.19918399e-05]),\n",
       " array([ 2.29316667e-01,  2.78673124e+00, -1.43268719e-01,  3.95272073e-05])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf672e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c2fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac20fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "1404\n"
     ]
    }
   ],
   "source": [
    "print(len(results.face_landmarks.landmark))\n",
    "print(len(results.face_landmarks.landmark)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a540ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4b39103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "777df92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ca4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662\n"
     ]
    }
   ],
   "source": [
    "faceModel = 468*3\n",
    "posModel = 33*4\n",
    "lhModel = 21*3\n",
    "rhModel = 21*3\n",
    "print(faceModel+posModel+lhModel+rhModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1b21dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35167658,  0.47473252, -0.93744594, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test = extract_keypoints(results)\n",
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "817a417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('0', result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69cf65fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35167658,  0.47473252, -0.93744594, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('0.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77672b",
   "metadata": {},
   "source": [
    "### Folder for Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea4a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01cd3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 8279-536C\n",
      "\n",
      " Directory of C:\\Users\\Shayan\n",
      "\n",
      "09/27/2022  04:05 PM    <DIR>          .\n",
      "09/27/2022  04:05 PM    <DIR>          ..\n",
      "02/22/2021  11:11 PM    <DIR>          .3T\n",
      "09/04/2021  12:47 PM    <DIR>          .android\n",
      "12/29/2021  09:29 PM    <DIR>          .aws\n",
      "12/29/2021  09:29 PM    <DIR>          .azure\n",
      "08/13/2022  09:03 AM            47,259 .bash_history\n",
      "08/13/2022  08:45 AM    <DIR>          .cache\n",
      "02/04/2021  04:28 PM    <DIR>          .cisco\n",
      "07/29/2022  06:05 PM    <DIR>          .conda\n",
      "07/29/2022  06:05 PM                25 .condarc\n",
      "07/29/2022  06:05 PM    <DIR>          .continuum\n",
      "02/16/2021  02:27 PM             1,324 .dbshell\n",
      "01/04/2022  02:48 PM    <DIR>          .docker\n",
      "08/01/2021  06:34 PM               143 .gitconfig\n",
      "02/17/2021  11:35 AM    <DIR>          .gradle\n",
      "08/19/2021  03:23 PM    <DIR>          .idlerc\n",
      "09/22/2022  09:26 AM    <DIR>          .ipynb_checkpoints\n",
      "12/28/2021  09:35 AM    <DIR>          .ipython\n",
      "02/10/2021  10:01 AM    <DIR>          .jdks\n",
      "09/22/2022  09:58 AM    <DIR>          .jupyter\n",
      "09/01/2022  09:18 PM    <DIR>          .keras\n",
      "02/10/2021  03:04 PM    <DIR>          .m2\n",
      "05/22/2022  06:28 PM    <DIR>          .matplotlib\n",
      "02/07/2021  12:29 PM                 0 .mongorc.js\n",
      "07/19/2021  08:42 PM    <DIR>          .ssh\n",
      "02/15/2021  02:37 PM    <DIR>          .swt\n",
      "09/28/2021  01:33 PM    <DIR>          .texlive2021\n",
      "02/09/2022  12:40 AM            15,661 .viminfo\n",
      "05/22/2022  09:28 AM    <DIR>          .VirtualBox\n",
      "05/22/2021  07:33 AM    <DIR>          .vscode\n",
      "03/28/2022  04:12 PM    <DIR>          .wdm\n",
      "09/27/2022  04:06 PM            13,424 0.npy\n",
      "02/05/2021  12:15 PM    <DIR>          3D Objects\n",
      "07/06/2022  07:55 PM           144,788 A.ipynb\n",
      "09/27/2022  04:05 PM            39,400 ActionDetectionforSignLanguage.ipynb\n",
      "09/08/2022  03:21 PM    <DIR>          anaconda3\n",
      "02/05/2021  12:15 PM    <DIR>          Contacts\n",
      "03/13/2021  12:31 PM    <DIR>          Creative Cloud Files\n",
      "09/27/2022  03:21 PM    <DIR>          Desktop\n",
      "09/16/2022  03:29 PM    <DIR>          Documents\n",
      "09/27/2022  09:37 AM    <DIR>          Downloads\n",
      "02/05/2021  12:15 PM    <DIR>          Favorites\n",
      "07/20/2022  06:00 PM             5,130 Filoger_1.ipynb\n",
      "03/11/2022  07:44 PM             3,258 gender_submission.csv\n",
      "03/15/2021  05:44 PM    <DIR>          IdeaProjects\n",
      "03/11/2022  08:31 PM             9,697 Kaggle_Titanic.ipynb\n",
      "02/05/2021  12:15 PM    <DIR>          Links\n",
      "09/25/2022  12:33 PM    <DIR>          MP_Data\n",
      "02/05/2021  12:15 PM    <DIR>          Music\n",
      "03/15/2022  03:48 PM             8,573 Numpy 1.ipynb\n",
      "08/09/2021  01:12 PM    <DIR>          OneDrive\n",
      "09/16/2022  12:11 PM    <DIR>          Pictures\n",
      "02/05/2021  12:15 PM    <DIR>          Saved Games\n",
      "07/09/2022  07:36 PM    <DIR>          seaborn-data\n",
      "02/27/2021  02:27 PM    <DIR>          Searches\n",
      "03/11/2022  07:44 PM            28,629 test.csv\n",
      "03/11/2022  07:44 PM            61,194 train.csv\n",
      "09/28/2021  02:15 PM                 0 untitled-1.aux\n",
      "09/28/2021  02:16 PM                 0 untitled-1.log\n",
      "09/28/2021  02:15 PM                 0 untitled-1.synctex(busy)\n",
      "09/28/2021  02:16 PM                67 untitled-1.tex\n",
      "06/08/2022  08:06 PM    <DIR>          Videos\n",
      "05/22/2022  08:32 AM    <DIR>          VirtualBox VMs\n",
      "12/29/2021  09:22 PM                 2 wsl\n",
      "              20 File(s)        378,574 bytes\n",
      "              45 Dir(s)  53,993,689,088 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2370ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6eadd0",
   "metadata": {},
   "source": [
    "### Collect Keypoints Values for Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecae8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # NEW LOOP\n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "#                 print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # NEW Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screenq\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b956dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6784/79584206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8eb756",
   "metadata": {},
   "source": [
    "### Preprocesss Data and Create label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b2d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78c719bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eb25bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'iloveyou': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7700427",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], [] #feature and train\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af8e7c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fda02beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5d0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5824e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "019f6afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9381a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6f7efa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e38e37",
   "metadata": {},
   "source": [
    "### Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8adba42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "005391c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a9e5aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa839c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape#for input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a440dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.shape[0]#number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d807bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [.7, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96048f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "294c8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17a82b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 5s 98ms/step - loss: 1.1510 - categorical_accuracy: 0.3529\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.1842 - categorical_accuracy: 0.3412\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.1013 - categorical_accuracy: 0.2824\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0943 - categorical_accuracy: 0.3412\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.2668 - categorical_accuracy: 0.2824\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 1.1003 - categorical_accuracy: 0.3412\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0692 - categorical_accuracy: 0.4235\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.1013 - categorical_accuracy: 0.3412\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0962 - categorical_accuracy: 0.3412\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.0973 - categorical_accuracy: 0.3412\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 1.0979 - categorical_accuracy: 0.3412\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.0978 - categorical_accuracy: 0.5529\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 1.0975 - categorical_accuracy: 0.3412\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.0972 - categorical_accuracy: 0.4941\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.0966 - categorical_accuracy: 0.5294\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.0954 - categorical_accuracy: 0.3529\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.0941 - categorical_accuracy: 0.3529\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0903 - categorical_accuracy: 0.3647\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.0816 - categorical_accuracy: 0.3765\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.0779 - categorical_accuracy: 0.3765\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 1.0720 - categorical_accuracy: 0.3647\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.0569 - categorical_accuracy: 0.3529\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 1.0186 - categorical_accuracy: 0.3529\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.9353 - categorical_accuracy: 0.3882\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.8428 - categorical_accuracy: 0.5059\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.7941 - categorical_accuracy: 0.6118\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.7304 - categorical_accuracy: 0.4471\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.3243 - categorical_accuracy: 0.6824\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.2095 - categorical_accuracy: 0.5882\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.2193 - categorical_accuracy: 0.4588\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.4259 - categorical_accuracy: 0.3412\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.0890 - categorical_accuracy: 0.3294\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.0865 - categorical_accuracy: 0.3294\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0833 - categorical_accuracy: 0.3294\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0627 - categorical_accuracy: 0.3294\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.9936 - categorical_accuracy: 0.3412\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.0868 - categorical_accuracy: 0.3412\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 1.0882 - categorical_accuracy: 0.3412\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 6.5921 - categorical_accuracy: 0.3294\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.0851 - categorical_accuracy: 0.3412\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.9963 - categorical_accuracy: 0.3294\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.9444 - categorical_accuracy: 0.3294\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0802 - categorical_accuracy: 0.3647\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.0789 - categorical_accuracy: 0.3529\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0461 - categorical_accuracy: 0.4941\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 17.5537 - categorical_accuracy: 0.3294\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 8.6279 - categorical_accuracy: 0.4353\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 29.7494 - categorical_accuracy: 0.4353\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.2249 - categorical_accuracy: 0.3529\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 38.8189 - categorical_accuracy: 0.3176\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 7.0004 - categorical_accuracy: 0.2118\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 9.4889 - categorical_accuracy: 0.3647\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 4.9025 - categorical_accuracy: 0.3176\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.0127 - categorical_accuracy: 0.5412\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.0138 - categorical_accuracy: 0.6706\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0182 - categorical_accuracy: 0.6000\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.9673 - categorical_accuracy: 0.6118\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 7.5859 - categorical_accuracy: 0.5647\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.9018 - categorical_accuracy: 0.4118\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.8520 - categorical_accuracy: 0.5412\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 5.0746 - categorical_accuracy: 0.6471\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 5.8806 - categorical_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 16.8696 - categorical_accuracy: 0.3176\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 20.7101 - categorical_accuracy: 0.3176\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 16.0263 - categorical_accuracy: 0.3529\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 7.6614 - categorical_accuracy: 0.4235\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 3.1891 - categorical_accuracy: 0.3294\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 2.8309 - categorical_accuracy: 0.2941\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 2.3390 - categorical_accuracy: 0.3647\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 2.5749 - categorical_accuracy: 0.4353\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 11.1563 - categorical_accuracy: 0.4235\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 6.2241 - categorical_accuracy: 0.4118\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 3.7619 - categorical_accuracy: 0.3529\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 7.0991 - categorical_accuracy: 0.4000\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 3.0980 - categorical_accuracy: 0.4000\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 6.5401 - categorical_accuracy: 0.2941\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 3.9628 - categorical_accuracy: 0.3529\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.0344 - categorical_accuracy: 0.4000\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 2.2552 - categorical_accuracy: 0.4118\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 4.0523 - categorical_accuracy: 0.3529\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 4.4255 - categorical_accuracy: 0.3412\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 2.5539 - categorical_accuracy: 0.2941\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 3.1203 - categorical_accuracy: 0.3882\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 3.4109 - categorical_accuracy: 0.2941\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 2.0910 - categorical_accuracy: 0.4706\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 2.8540 - categorical_accuracy: 0.2941\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 1.8940 - categorical_accuracy: 0.3176\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 1.6332 - categorical_accuracy: 0.3176\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 1.7190 - categorical_accuracy: 0.2941\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.5785 - categorical_accuracy: 0.3294\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.3742 - categorical_accuracy: 0.2235\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 1.1339 - categorical_accuracy: 0.4000\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.1735 - categorical_accuracy: 0.3647\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 1.0646 - categorical_accuracy: 0.5412\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.1062 - categorical_accuracy: 0.3647\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.9531 - categorical_accuracy: 0.6471\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.9444 - categorical_accuracy: 0.6118\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.9312 - categorical_accuracy: 0.7412\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.9280 - categorical_accuracy: 0.5059\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.9169 - categorical_accuracy: 0.5647\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.8961 - categorical_accuracy: 0.5529\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.9575 - categorical_accuracy: 0.5059\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.8901 - categorical_accuracy: 0.5882\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.9406 - categorical_accuracy: 0.5294\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.0370 - categorical_accuracy: 0.5412\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.0444 - categorical_accuracy: 0.4824\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.9366 - categorical_accuracy: 0.5294\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.8711 - categorical_accuracy: 0.5176\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.8710 - categorical_accuracy: 0.5294\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.8459 - categorical_accuracy: 0.5647\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.8791 - categorical_accuracy: 0.5882\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.7550 - categorical_accuracy: 0.6706\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.7592 - categorical_accuracy: 0.6235\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.7658 - categorical_accuracy: 0.7176\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.7085 - categorical_accuracy: 0.6588\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.7056 - categorical_accuracy: 0.6824\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.6945 - categorical_accuracy: 0.7294\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.6602 - categorical_accuracy: 0.6353\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.6306 - categorical_accuracy: 0.6824\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.6603 - categorical_accuracy: 0.7412\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.5900 - categorical_accuracy: 0.7176\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.6232 - categorical_accuracy: 0.6706\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.5725 - categorical_accuracy: 0.7294\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.5333 - categorical_accuracy: 0.8353\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.4974 - categorical_accuracy: 0.8235\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.4900 - categorical_accuracy: 0.8471\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.4603 - categorical_accuracy: 0.8941\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.4256 - categorical_accuracy: 0.8588\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.4264 - categorical_accuracy: 0.8824\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.4153 - categorical_accuracy: 0.8941\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.4096 - categorical_accuracy: 0.8235\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.4053 - categorical_accuracy: 0.8824\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.4085 - categorical_accuracy: 0.8706\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.4228 - categorical_accuracy: 0.8588\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3856 - categorical_accuracy: 0.9176\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3724 - categorical_accuracy: 0.8588\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3756 - categorical_accuracy: 0.8706\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.3479 - categorical_accuracy: 0.8824\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3516 - categorical_accuracy: 0.8353\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3293 - categorical_accuracy: 0.9176\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.3388 - categorical_accuracy: 0.9176\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3507 - categorical_accuracy: 0.8471\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3125 - categorical_accuracy: 0.8588\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3770 - categorical_accuracy: 0.8941\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.3839 - categorical_accuracy: 0.8118\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 1.3607 - categorical_accuracy: 0.6471\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.6841 - categorical_accuracy: 0.7176\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 1.0538 - categorical_accuracy: 0.6471\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.8809 - categorical_accuracy: 0.6000\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.6690 - categorical_accuracy: 0.6706\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.7773 - categorical_accuracy: 0.6588\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.4876 - categorical_accuracy: 0.7647\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.5180 - categorical_accuracy: 0.6824\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.4274 - categorical_accuracy: 0.8824\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3905 - categorical_accuracy: 0.8706\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.3963 - categorical_accuracy: 0.8235\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3652 - categorical_accuracy: 0.9059\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3645 - categorical_accuracy: 0.8941\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.3524 - categorical_accuracy: 0.8706\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.3475 - categorical_accuracy: 0.9059\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3339 - categorical_accuracy: 0.9176\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.3402 - categorical_accuracy: 0.8706\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3343 - categorical_accuracy: 0.8706\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3201 - categorical_accuracy: 0.9176\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.3080 - categorical_accuracy: 0.9176\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.3588 - categorical_accuracy: 0.8235\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3509 - categorical_accuracy: 0.8824\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.3479 - categorical_accuracy: 0.9176\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.4556 - categorical_accuracy: 0.7765\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.3448 - categorical_accuracy: 0.8588\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.3501 - categorical_accuracy: 0.8706\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3064 - categorical_accuracy: 0.8588\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.3024 - categorical_accuracy: 0.8706\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.3216 - categorical_accuracy: 0.9176\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.2940 - categorical_accuracy: 0.8706\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.2838 - categorical_accuracy: 0.8941\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2872 - categorical_accuracy: 0.9059\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.2884 - categorical_accuracy: 0.8706\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.2596 - categorical_accuracy: 0.9176\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.2520 - categorical_accuracy: 0.9176\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.2539 - categorical_accuracy: 0.8941\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.2590 - categorical_accuracy: 0.9176\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2419 - categorical_accuracy: 0.9176\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2767 - categorical_accuracy: 0.9176\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2541 - categorical_accuracy: 0.8941\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2431 - categorical_accuracy: 0.9059\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.2516 - categorical_accuracy: 0.9176\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2413 - categorical_accuracy: 0.9294\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2360 - categorical_accuracy: 0.9294\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2441 - categorical_accuracy: 0.9294\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2426 - categorical_accuracy: 0.9176\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2265 - categorical_accuracy: 0.9176\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.2434 - categorical_accuracy: 0.9412\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2414 - categorical_accuracy: 0.9176\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2295 - categorical_accuracy: 0.9176\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2438 - categorical_accuracy: 0.9294\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2226 - categorical_accuracy: 0.9176\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2262 - categorical_accuracy: 0.9294\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2323 - categorical_accuracy: 0.9294\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2280 - categorical_accuracy: 0.9059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24289498640>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ecc73f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95accd55",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f3f5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 562ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80afd776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.97462666e-01, 1.02376565e-01, 1.60717609e-04],\n",
       "       [1.53838441e-01, 7.36567676e-01, 1.09593935e-01],\n",
       "       [6.74021840e-01, 3.24313104e-01, 1.66509917e-03],\n",
       "       [1.84346288e-01, 7.12100625e-01, 1.03553079e-01],\n",
       "       [2.22025858e-03, 5.59606776e-02, 9.41819072e-01]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cce016ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iloveyou'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26ee7706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iloveyou'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157b140",
   "metadata": {},
   "source": [
    "### Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b73253ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a55eaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5edd9",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa066d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d35529f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db799161",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()#like on hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c890730a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 2, 1]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86446842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 0],\n",
       "        [0, 3]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [0, 2]]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e8d0fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5a037",
   "metadata": {},
   "source": [
    "### Test in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8a3a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c82443f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "iloveyou\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "iloveyou\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "#         sequence.insert(0,keypoints)\n",
    "#         sequence = sequence[:30]\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]#last keypoints\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb7623ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6be7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7ea1dfb28780cb7412353a3ec0c3d0a6bf48b6a5903db3c2edca4efca070eeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
